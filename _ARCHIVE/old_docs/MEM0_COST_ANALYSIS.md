# ğŸ’° mem0 Token Cost Analysis

**Dato:** 17. November 2025

## ğŸ“Š OpenRouter Pricing (2025)

### Current Setup:
- **LLM:** `openai/gpt-4o-mini`
- **Embedding:** `text-embedding-3-small`
- **Vector DB:** Qdrant (local, gratis)

### Costs:

| Component | Input | Output |
|-----------|-------|--------|
| GPT-4o-mini | $0.15 / 1M tokens | $0.60 / 1M tokens |
| text-embedding-3-small | $0.02 / 1M tokens | $0 (no output) |

**Conversion:**
- GPT-4o-mini: $0.00015/1k input, $0.00060/1k output
- Embeddings: $0.00002/1k tokens

---

## ğŸ” Actual Costs per Operation

### 1. Memory Search (`mcp__mem0__search_memories`)

**What happens:**
1. Your query gets embedded (~50-100 tokens)
2. Qdrant vector search (local, free)
3. LLM extracts relevant memories (~500 tokens input + 200 output)

**Cost per search:**
```
Embedding: 100 tokens Ã— $0.00002/1k = $0.000002
LLM input: 500 tokens Ã— $0.00015/1k = $0.000075
LLM output: 200 tokens Ã— $0.00060/1k = $0.000120
----------------------------------------
TOTAL: ~$0.0002 per search (~0.02 Ã¸re)
```

### 2. Memory Save (`mcp__mem0__save_memory`)

**What happens:**
1. Content gets embedded (~500-1000 tokens)
2. LLM extracts/processes memory (~1000 input + 300 output)
3. Qdrant stores vector (local, free)

**Cost per save:**
```
Embedding: 1000 tokens Ã— $0.00002/1k = $0.00002
LLM input: 1000 tokens Ã— $0.00015/1k = $0.00015
LLM output: 300 tokens Ã— $0.00060/1k = $0.00018
----------------------------------------
TOTAL: ~$0.00035 per save (~0.035 Ã¸re)
```

### 3. Get All Memories (`mcp__mem0__get_all_memories`)

**What happens:**
1. Direct database fetch (Qdrant local, free)
2. Optional LLM formatting (~500 input + 200 output)

**Cost:**
```
LLM input: 500 tokens Ã— $0.00015/1k = $0.000075
LLM output: 200 tokens Ã— $0.00060/1k = $0.000120
----------------------------------------
TOTAL: ~$0.0002 per get_all (~0.02 Ã¸re)
```

---

## ğŸ“ˆ Monthly Estimates

**Scenario: Active AIKI usage**

| Activity | Operations/day | Cost/op | Daily | Monthly |
|----------|----------------|---------|-------|---------|
| Search memories | 50 | $0.0002 | $0.01 | $0.30 |
| Save memories | 20 | $0.00035 | $0.007 | $0.21 |
| Get all | 5 | $0.0002 | $0.001 | $0.03 |
| **TOTAL** | | | **$0.018** | **$0.54** |

**~5.50 kr/mÃ¥ned** (~54 Ã¸re/dag)

---

## ğŸ¯ Optimalisering

### Problem med current flow:
- âŒ Claude Code mÃ¥ STOPPE og VENTE pÃ¥ mem0 operasjoner
- âŒ Hver search/save blokkerer conversation flow
- âŒ Context switches distraherer (ADHD problem!)

### LÃ¸sning: Bakgrunnsprosess + Triggerord

#### 1. **Background Memory Daemon**
```python
# ~/aiki/memory_daemon.py
# KjÃ¸rer i bakgrunnen, lytter pÃ¥ file changes
# Auto-lagrer til mem0 uten Ã¥ blokkere Claude Code
```

**Benefits:**
- âœ… Zero interruption til conversation
- âœ… Auto-save pÃ¥ file changes
- âœ… Async processing (ikke blokkerende)
- âœ… Batch operations (billigere!)

#### 2. **Triggerord for Auto-Search**

**Konsept:** Claude Code detekterer keywords og sÃ¸ker mem0 automatisk

**Eksempler:**
- User: "Hva er AIKI-HOME?" â†’ Auto-search: "AIKI-HOME"
- User: "Fortsett med input monitor" â†’ Auto-search: "input monitor"
- User: "Sist vi jobbet med..." â†’ Auto-search: "last session"

**Implementation:**
```python
# I Claude Code hook (pre-prompt processing)
TRIGGER_PATTERNS = {
    r"hva er (\w+)": lambda m: f"search: {m.group(1)}",
    r"fortsett med (\w+)": lambda m: f"search: {m.group(1)}",
    r"sist vi jobbet": lambda: "search: last session recent work"
}

# Auto-inject search results into context
# Claude sees results WITHOUT explicit tool call
```

#### 3. **Batch Embeddings**

**Current:** Each save = 1 embedding call
**Better:** Batch multiple saves

```python
# Instead of:
save("memory 1")  # $0.00035
save("memory 2")  # $0.00035
save("memory 3")  # $0.00035

# Do:
batch_save(["memory 1", "memory 2", "memory 3"])  # $0.00040
# 60% kostnad reduksjon!
```

---

## ğŸš€ Proposed Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Claude Code Session             â”‚
â”‚  (No mem0 blocking - seamless flow!)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â”‚ File changes detected
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Memory Daemon (background)        â”‚
â”‚  - Watch file system (inotify)          â”‚
â”‚  - Detect new/changed files             â”‚
â”‚  - Extract summaries                    â”‚
â”‚  - Batch save to mem0                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â”‚ Async writes
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              mem0 + Qdrant              â”‚
â”‚  - Embeddings generated in batch        â”‚
â”‚  - Stored locally (instant access)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Triggerord Preprocessor            â”‚
â”‚  - Scan user messages for keywords      â”‚
â”‚  - Auto-inject relevant memories        â”‚
â”‚  - Zero user action required            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’ Implementation Plan

### Phase 1: Background Daemon (2-3 timer)
1. `memory_daemon.py` - watch aiki-home/ for changes
2. Auto-extract summaries from modified files
3. Batch save to mem0 every 5 minutes
4. systemd service for auto-start

### Phase 2: Triggerord System (1-2 timer)
1. Add pre-processing hook to Claude Code
2. Pattern matching for common queries
3. Auto-inject search results into context
4. Transparent to user (no tool calls visible)

### Phase 3: Cost Optimization (1 time)
1. Batch embedding calls
2. Cache frequent searches (Redis?)
3. Use cheaper models for simple extractions

---

## ğŸ“‰ Expected Savings

| Metric | Before | After | Improvement |
|--------|--------|-------|-------------|
| Conversation interruptions | 10-20/session | 0 | 100% |
| Time to context | 5-10 sec | 0 sec | Instant |
| Token cost | $0.54/month | $0.30/month | 45% savings |
| ADHD-friendliness | 3/10 | 10/10 | ğŸš€ |

---

## âœ… Conclusion

**Current cost: Neglisjerbar (~5 kr/mÃ¥ned)**

**Real problem: IKKE kostnad, men FLOW!**
- Stopping to save/search breaks ADHD flow
- Manual operations create friction
- Context switches hurt productivity

**Solution: Background automation**
- Memory daemon handles saves automatically
- Triggerord system injects context seamlessly
- Zero user action = zero friction = ADHD heaven

**Next step:** Build memory daemon + triggerord preprocessor

---

**Made with ğŸ§  by AIKI**
